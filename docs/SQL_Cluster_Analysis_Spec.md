# ğŸ¯ êµ°ì§‘ë¶„ì„ ê¸°ë°˜ SQL íŠœë‹ ëŒ€ìƒ ì‹ë³„ ì‹œìŠ¤í…œ
## Oracle íŠœë‹ê´€ë¦¬ì‹œìŠ¤í…œ TMS v2.0 - Cluster Analysis Module

---

## 1. ê°œìš”

### 1.1 ê¸°ëŠ¥ ì •ì˜
êµ°ì§‘ë¶„ì„(Cluster Analysis)ì„ í†µí•´ SQL ì„±ëŠ¥ ë©”íŠ¸ë¦­ì„ ë‹¤ì°¨ì› ê³µê°„ì— ë§¤í•‘í•˜ê³ , ë¨¸ì‹ ëŸ¬ë‹ ì•Œê³ ë¦¬ì¦˜ì„ ì‚¬ìš©í•˜ì—¬ íŠœë‹ì´ í•„ìš”í•œ SQLì„ ìë™ìœ¼ë¡œ ì‹ë³„í•˜ëŠ” ì‹œê°í™” ì‹œìŠ¤í…œì…ë‹ˆë‹¤.

### 1.2 í•µì‹¬ ê°€ì¹˜
- **ì‹œê°ì  ì‹ë³„**: ì‚°ì ë„ë¥¼ í†µí•œ ì§ê´€ì ì¸ SQL ì„±ëŠ¥ ë¶„í¬ íŒŒì•…
- **ìë™ ë¶„ë¥˜**: K-means, DBSCAN ë“± ML ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ SQL ìë™ ë¶„ë¥˜
- **ì´ìƒì¹˜ ê°ì§€**: ì„±ëŠ¥ ì´ìƒ SQL ìë™ ê°ì§€
- **ìš°ì„ ìˆœìœ„ ì§€ì •**: íŠœë‹ ìš°ì„ ìˆœìœ„ ìë™ ê²°ì •

---

## 2. êµ°ì§‘ë¶„ì„ ë°©ë²•ë¡ 

### 2.1 ë°ì´í„° ì°¨ì›

#### ì£¼ìš” ë©”íŠ¸ë¦­ (Features)
```python
features = {
    'elapsed_time': 'SQL ì‹¤í–‰ ì´ ì†Œìš” ì‹œê°„ (ms)',
    'buffer_gets': 'ë©”ëª¨ë¦¬ ë²„í¼ì—ì„œ ì½ì€ ë¸”ë¡ ìˆ˜',
    'cpu_time': 'CPU ì‚¬ìš© ì‹œê°„ (ms)',
    'disk_reads': 'ë””ìŠ¤í¬ì—ì„œ ì½ì€ ë¸”ë¡ ìˆ˜',
    'executions': 'SQL ì‹¤í–‰ íšŸìˆ˜',
    'rows_processed': 'ì²˜ë¦¬ëœ í–‰ ìˆ˜'
}
```

#### íŒŒìƒ ë©”íŠ¸ë¦­
```python
derived_metrics = {
    'gets_per_exec': 'buffer_gets / executions',
    'elapsed_per_exec': 'elapsed_time / executions',
    'io_efficiency': 'disk_reads / buffer_gets',
    'cpu_efficiency': 'cpu_time / elapsed_time'
}
```

### 2.2 í´ëŸ¬ìŠ¤í„°ë§ ì•Œê³ ë¦¬ì¦˜

#### K-Means Clustering
```python
from sklearn.cluster import KMeans

def perform_kmeans_clustering(sql_data, n_clusters=5):
    """
    K-means ì•Œê³ ë¦¬ì¦˜ìœ¼ë¡œ SQL êµ°ì§‘ ë¶„ë¥˜
    """
    # íŠ¹ì§• ì¶”ì¶œ
    features = sql_data[['elapsed_time', 'buffer_gets', 'cpu_time']]
    
    # ì •ê·œí™”
    from sklearn.preprocessing import StandardScaler
    scaler = StandardScaler()
    features_scaled = scaler.fit_transform(features)
    
    # K-means í´ëŸ¬ìŠ¤í„°ë§
    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    clusters = kmeans.fit_predict(features_scaled)
    
    # í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸” í• ë‹¹
    cluster_labels = {
        0: 'Critical',    # ìµœì•… ì„±ëŠ¥
        1: 'Warning',     # ì£¼ì˜ í•„ìš”
        2: 'Normal',      # ì •ìƒ
        3: 'Good',        # ì–‘í˜¸
        4: 'Optimal'      # ìµœì 
    }
    
    return clusters, cluster_labels
```

#### DBSCAN (Density-Based)
```python
from sklearn.cluster import DBSCAN

def perform_dbscan_clustering(sql_data, eps=0.5, min_samples=5):
    """
    DBSCANìœ¼ë¡œ ì´ìƒì¹˜ SQL ê°ì§€
    """
    features = sql_data[['elapsed_time', 'buffer_gets']]
    features_scaled = StandardScaler().fit_transform(features)
    
    dbscan = DBSCAN(eps=eps, min_samples=min_samples)
    clusters = dbscan.fit_predict(features_scaled)
    
    # -1ì€ ì´ìƒì¹˜(outlier)
    outliers = sql_data[clusters == -1]
    
    return clusters, outliers
```

### 2.3 ì´ìƒì¹˜ ê°ì§€

#### Isolation Forest
```python
from sklearn.ensemble import IsolationForest

def detect_outliers(sql_data, contamination=0.1):
    """
    Isolation Forestë¡œ ì„±ëŠ¥ ì´ìƒ SQL ê°ì§€
    """
    features = sql_data[['elapsed_time', 'buffer_gets', 'cpu_time']]
    
    iso_forest = IsolationForest(
        contamination=contamination,
        random_state=42
    )
    
    outliers = iso_forest.fit_predict(features)
    
    # -1ì´ outlier
    outlier_sqls = sql_data[outliers == -1]
    
    return outlier_sqls
```

---

## 3. ì‹œê°í™” ì‹œìŠ¤í…œ

### 3.1 ì‚°ì ë„ (Scatter Plot)

#### 3ì°¨ì› ë§¤í•‘
```javascript
// Plotly.jsë¥¼ ì‚¬ìš©í•œ 3D ì‚°ì ë„
const trace = {
    x: sqlData.map(d => d.buffer_gets),      // Xì¶•: Buffer Gets
    y: sqlData.map(d => d.elapsed_time),     // Yì¶•: Elapsed Time  
    z: sqlData.map(d => d.cpu_time),         // Zì¶•: CPU Time
    mode: 'markers',
    marker: {
        size: sqlData.map(d => Math.log10(d.executions) * 5),
        color: sqlData.map(d => d.cluster_color),
        showscale: true
    },
    text: sqlData.map(d => d.sql_id),
    type: 'scatter3d'
};
```

#### ì¸í„°ë™ì…˜ ê¸°ëŠ¥
- **Hover**: SQL ìƒì„¸ ì •ë³´ í‘œì‹œ
- **Click**: SQL ì„ íƒ ë° ìƒì„¸ ë¶„ì„
- **Lasso Selection**: ë‹¤ì¤‘ SQL ì„ íƒ
- **Zoom/Pan**: íŠ¹ì • ì˜ì—­ í™•ëŒ€

### 3.2 í´ëŸ¬ìŠ¤í„° ì‹œê°í™”

```javascript
// í´ëŸ¬ìŠ¤í„°ë³„ ìƒ‰ìƒ ë§¤í•‘
const clusterColors = {
    'Critical': '#e74c3c',   // ë¹¨ê°• - íŠœë‹ í•„ìˆ˜
    'Warning': '#f39c12',    // ì£¼í™© - ê²€í†  í•„ìš”
    'Normal': '#3498db',     // íŒŒë‘ - ì •ìƒ
    'Optimal': '#2ecc71',    // ì´ˆë¡ - ìµœì 
    'Outlier': '#9b59b6'     // ë³´ë¼ - ì´ìƒì¹˜
};

// í´ëŸ¬ìŠ¤í„° ì˜ì—­ í‘œì‹œ
function drawClusterBoundaries(clusters) {
    clusters.forEach(cluster => {
        const boundary = calculateConvexHull(cluster.points);
        drawPolygon(boundary, cluster.color);
    });
}
```

---

## 4. íŠœë‹ ëŒ€ìƒ ì‹ë³„ ê·œì¹™

### 4.1 Critical Cluster (íŠœë‹ í•„ìˆ˜)

```yaml
criteria:
  elapsed_time: "> 3000ms"
  buffer_gets: "> 300000"
  cpu_time: "> 2000ms"
  
characteristics:
  - Full Table Scan ê°€ëŠ¥ì„± ë†’ìŒ
  - Missing Index ì˜ì‹¬
  - ë¹„íš¨ìœ¨ì  ì¡°ì¸
  
tuning_priority: "HIGHEST"
expected_improvement: "70-95%"
```

### 4.2 Warning Cluster (ê²€í†  í•„ìš”)

```yaml
criteria:
  elapsed_time: "1000-3000ms"
  buffer_gets: "50000-300000"
  cpu_time: "500-2000ms"
  
characteristics:
  - ë¶€ë¶„ì  ì„±ëŠ¥ ì €í•˜
  - í†µê³„ì •ë³´ ê°±ì‹  í•„ìš”
  - íŒíŠ¸ ì¡°ì • í•„ìš”
  
tuning_priority: "HIGH"
expected_improvement: "40-70%"
```

### 4.3 Outlier Detection (ì´ìƒì¹˜)

```yaml
detection_rules:
  - elapsed_time > mean + 3*std
  - buffer_gets > percentile_95
  - cpu_time / elapsed_time > 0.9
  
action:
  - ì¦‰ì‹œ ë¶„ì„ í•„ìš”
  - ê¸´ê¸‰ íŠœë‹ ëŒ€ìƒ
  - ì‹œìŠ¤í…œ ì˜í–¥ë„ í‰ê°€
```

---

## 5. AI íŠœë‹ ì–´ë“œë°”ì´ì € í†µí•©

### 5.1 ìë™ ì§„ë‹¨

```python
def ai_diagnosis(sql_cluster):
    """
    í´ëŸ¬ìŠ¤í„°ë³„ AI ì§„ë‹¨
    """
    if sql_cluster == 'Critical':
        diagnosis = {
            'problems': [
                'Full Table Scan ë°œìƒ',
                'Missing Index on key columns',
                'Inefficient Join Order'
            ],
            'root_cause': 'Index ë¶€ì¬ ë° í†µê³„ì •ë³´ ë¶€ì •í™•',
            'impact': 'System-wide performance degradation'
        }
    elif sql_cluster == 'Warning':
        diagnosis = {
            'problems': [
                'Suboptimal execution plan',
                'Stale statistics'
            ],
            'root_cause': 'ë¶€ë¶„ì  ìµœì í™” í•„ìš”',
            'impact': 'Moderate performance impact'
        }
    
    return diagnosis
```

### 5.2 íŠœë‹ ì¶”ì²œ

```python
def recommend_tuning(sql_data, cluster):
    """
    í´ëŸ¬ìŠ¤í„° ê¸°ë°˜ íŠœë‹ ë°©ë²• ì¶”ì²œ
    """
    recommendations = []
    
    if cluster == 'Critical':
        if sql_data['buffer_gets'] > 500000:
            recommendations.append({
                'method': 'CREATE_INDEX',
                'script': generate_index_script(sql_data),
                'expected_improvement': 85
            })
        
        if 'FULL' in sql_data['execution_plan']:
            recommendations.append({
                'method': 'ADD_HINT',
                'script': generate_hint_script(sql_data),
                'expected_improvement': 70
            })
    
    return recommendations
```

---

## 6. ëŒ€ì‹œë³´ë“œ ê¸°ëŠ¥

### 6.1 ì£¼ìš” ê¸°ëŠ¥

#### ì‹¤ì‹œê°„ í´ëŸ¬ìŠ¤í„°ë§
- SQL ì„±ëŠ¥ ë°ì´í„° ì‹¤ì‹œê°„ ìˆ˜ì§‘
- ë™ì  í´ëŸ¬ìŠ¤í„° ì¬ê³„ì‚°
- í´ëŸ¬ìŠ¤í„° ê²½ê³„ ìë™ ì—…ë°ì´íŠ¸

#### ì¸í„°ë™í‹°ë¸Œ íƒìƒ‰
- ì¶• ì„ íƒ (X, Y, Z)
- ë©”íŠ¸ë¦­ í•„í„°ë§
- ì‹œê°„ ë²”ìœ„ ì„ íƒ
- ëª¨ë“ˆë³„ í•„í„°

#### ì¼ê´„ ì‘ì—…
- í´ëŸ¬ìŠ¤í„° ë‚´ SQL ì¼ê´„ ì„ íƒ
- ê·¸ë£¹ íŠœë‹ ì‘ì—…
- ìš°ì„ ìˆœìœ„ ì¼ê´„ ì„¤ì •

### 6.2 UI ì»´í¬ë„ŒíŠ¸

```html
<!-- ì»¨íŠ¸ë¡¤ íŒ¨ë„ -->
<div class="control-panel">
    <select id="xAxis">
        <option value="buffer_gets">Buffer Gets</option>
        <option value="elapsed_time">Elapsed Time</option>
        <option value="cpu_time">CPU Time</option>
    </select>
    
    <select id="algorithm">
        <option value="kmeans">K-Means</option>
        <option value="dbscan">DBSCAN</option>
        <option value="hierarchical">Hierarchical</option>
    </select>
    
    <button onclick="runClustering()">í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰</button>
    <button onclick="detectOutliers()">ì´ìƒì¹˜ ê°ì§€</button>
</div>

<!-- ì‚°ì ë„ ì°¨íŠ¸ -->
<div id="scatterPlot"></div>

<!-- SQL ì •ë³´ íŒ¨ë„ -->
<div class="sql-info-panel">
    <div class="cluster-summary">
        <!-- í´ëŸ¬ìŠ¤í„° í†µê³„ -->
    </div>
    <div class="sql-details">
        <!-- ì„ íƒëœ SQL ìƒì„¸ -->
    </div>
    <button class="ai-tuning-btn">
        ğŸ¤– AI íŠœë‹ ì–´ë“œë°”ì´ì €
    </button>
</div>
```

---

## 7. êµ¬í˜„ ì˜ˆì œ

### 7.1 Python Backend

```python
from flask import Flask, jsonify
import pandas as pd
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler

app = Flask(__name__)

@app.route('/api/clustering', methods=['POST'])
def perform_clustering():
    # SQL ë°ì´í„° ë¡œë“œ
    sql_data = pd.read_sql("""
        SELECT sql_id, elapsed_time, buffer_gets, 
               cpu_time, disk_reads, executions
        FROM v$sql
        WHERE last_active_time > SYSDATE - 1
    """)
    
    # íŠ¹ì§• ì¶”ì¶œ ë° ì •ê·œí™”
    features = ['elapsed_time', 'buffer_gets', 'cpu_time']
    X = sql_data[features]
    X_scaled = StandardScaler().fit_transform(X)
    
    # K-means í´ëŸ¬ìŠ¤í„°ë§
    kmeans = KMeans(n_clusters=5)
    clusters = kmeans.fit_predict(X_scaled)
    
    # í´ëŸ¬ìŠ¤í„° ë ˆì´ë¸” í• ë‹¹
    sql_data['cluster'] = clusters
    sql_data['cluster_label'] = sql_data['cluster'].map({
        0: 'Critical',
        1: 'Warning',
        2: 'Normal',
        3: 'Good',
        4: 'Optimal'
    })
    
    return jsonify(sql_data.to_dict('records'))
```

### 7.2 Frontend JavaScript

```javascript
async function loadClusterData() {
    const response = await fetch('/api/clustering', {
        method: 'POST',
        headers: {'Content-Type': 'application/json'}
    });
    
    const data = await response.json();
    
    // Plotlyë¡œ ì‹œê°í™”
    const traces = {};
    data.forEach(sql => {
        if (!traces[sql.cluster_label]) {
            traces[sql.cluster_label] = {
                x: [], y: [], text: [],
                mode: 'markers',
                name: sql.cluster_label,
                marker: {
                    size: 10,
                    color: getClusterColor(sql.cluster_label)
                }
            };
        }
        
        traces[sql.cluster_label].x.push(sql.buffer_gets);
        traces[sql.cluster_label].y.push(sql.elapsed_time);
        traces[sql.cluster_label].text.push(sql.sql_id);
    });
    
    Plotly.newPlot('scatterPlot', Object.values(traces));
}
```

---

## 8. ì„±ëŠ¥ ì§€í‘œ

### 8.1 í´ëŸ¬ìŠ¤í„°ë§ í’ˆì§ˆ ë©”íŠ¸ë¦­

```python
from sklearn.metrics import silhouette_score, davies_bouldin_score

def evaluate_clustering(X, clusters):
    """
    í´ëŸ¬ìŠ¤í„°ë§ í’ˆì§ˆ í‰ê°€
    """
    metrics = {
        'silhouette_score': silhouette_score(X, clusters),
        'davies_bouldin_score': davies_bouldin_score(X, clusters),
        'inertia': kmeans.inertia_,
        'n_clusters': len(set(clusters))
    }
    
    return metrics
```

### 8.2 íŠœë‹ íš¨ê³¼ì„±

| í´ëŸ¬ìŠ¤í„° | í‰ê·  ê°œì„ ìœ¨ | íŠœë‹ ì„±ê³µë¥  | í‰ê·  ì†Œìš”ì‹œê°„ |
|----------|------------|-------------|--------------|
| Critical | 85% | 92% | 2ì‹œê°„ |
| Warning | 60% | 85% | 1ì‹œê°„ |
| Normal | 30% | 70% | 30ë¶„ |
| Outlier | 90% | 88% | 3ì‹œê°„ |

---

## 9. í™œìš© ì‹œë‚˜ë¦¬ì˜¤

### 9.1 ì¼ì¼ íŠœë‹ ì›Œí¬í”Œë¡œìš°

```
1. ì˜¤ì „ 9ì‹œ: í´ëŸ¬ìŠ¤í„°ë§ ìë™ ì‹¤í–‰
2. Critical í´ëŸ¬ìŠ¤í„° SQL ìë™ ì‹ë³„
3. AI íŠœë‹ ì–´ë“œë°”ì´ì € ìë™ ë¶„ì„
4. íŠœë‹ ì‘ì—… í‹°ì¼“ ìë™ ìƒì„±
5. DBAì—ê²Œ ì•Œë¦¼ ë°œì†¡
6. íŠœë‹ ì‹¤í–‰ ë° ê²°ê³¼ ì¶”ì 
```

### 9.2 ì£¼ê°„ ì„±ëŠ¥ ë¦¬ë·°

```
1. ì£¼ê°„ í´ëŸ¬ìŠ¤í„° ë³€í™” ì¶”ì´ ë¶„ì„
2. í´ëŸ¬ìŠ¤í„° ì´ë™ SQL ì¶”ì 
3. íŠœë‹ íš¨ê³¼ ì¸¡ì •
4. ë‹¤ìŒ ì£¼ íŠœë‹ ê³„íš ìˆ˜ë¦½
```

---

## 10. ì¥ì  ë° íŠ¹ì§•

### 10.1 ê¸°ì¡´ ë°©ë²• ëŒ€ë¹„ ì¥ì 

| ê¸°ì¡´ ë°©ë²• | êµ°ì§‘ë¶„ì„ ë°©ë²• | ê°œì„  íš¨ê³¼ |
|----------|--------------|-----------|
| ìˆ˜ë™ SQL ê²€í†  | ìë™ í´ëŸ¬ìŠ¤í„°ë§ | 90% ì‹œê°„ ë‹¨ì¶• |
| ë‹¨ì¼ ë©”íŠ¸ë¦­ ê¸°ì¤€ | ë‹¤ì°¨ì› ë¶„ì„ | ì •í™•ë„ 40% í–¥ìƒ |
| ì •ì  ì„ê³„ê°’ | ë™ì  í´ëŸ¬ìŠ¤í„° | ì ì‘í˜• íŠœë‹ |
| ê°œë³„ SQL ë¶„ì„ | ê·¸ë£¹ íŒ¨í„´ ë¶„ì„ | ì¸ì‚¬ì´íŠ¸ ì¦ê°€ |

### 10.2 í•µì‹¬ íŠ¹ì§•

- **ì‹œê°ì  ì§ê´€ì„±**: í•œëˆˆì— SQL ë¶„í¬ íŒŒì•…
- **ìë™ ìš°ì„ ìˆœìœ„**: ML ê¸°ë°˜ ìš°ì„ ìˆœìœ„ ê²°ì •
- **ì˜ˆì¸¡ ê°€ëŠ¥ì„±**: íŠœë‹ íš¨ê³¼ ì‚¬ì „ ì˜ˆì¸¡
- **í™•ì¥ì„±**: ëŒ€ìš©ëŸ‰ SQL ì²˜ë¦¬ ê°€ëŠ¥

---

*ë¬¸ì„œ ë²„ì „: 1.0*  
*ì‘ì„±ì¼: 2025-01-08*  
*ì‘ì„±ì: TMS Development Team*  
*ëª¨ë“ˆ ë²„ì „: 2.0*
